{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1d2f608",
   "metadata": {},
   "source": [
    "# Geospatial Machine Learning Pipeline for Binary Classification\n",
    "\n",
    "This notebook implements a PCA-based machine learning pipeline for geospatial binary classification.\n",
    "Originally developed for archaeological site prediction but can be adapted for any geospatial \n",
    "binary classification problem (e.g., landslide susceptibility, urban planning, habitat modeling).\n",
    "\n",
    "## Requirements:\n",
    "1. Point data with coordinates and binary class labels\n",
    "2. Raster data covering the study area\n",
    "3. All data in same coordinate reference system\n",
    "\n",
    "## Usage:\n",
    "1. Update file paths in the configuration section\n",
    "2. Modify class_type_mapping for your specific classes  \n",
    "3. Adjust raster_files dictionary based on your available data\n",
    "4. Run the pipeline\n",
    "\n",
    "**Author:** [Your name]  \n",
    "**Paper:** [Paper title/link when published]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31fc3de",
   "metadata": {},
   "source": [
    "## 1. Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b79f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "!pip install pandas rasterio numpy matplotlib seaborn scikit-learn xgboost scipy statsmodels imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b06bb7",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22cec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from matplotlib.colors import ListedColormap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0726ee0d",
   "metadata": {},
   "source": [
    "## 3. Configuration Section\n",
    "**⚠️ UPDATE THESE PATHS AND SETTINGS FOR YOUR DATA ⚠️**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0600f7a2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION SECTION - UPDATE THESE PATHS AND SETTINGS FOR YOUR DATA\n",
    "# =============================================================================\n",
    "\n",
    "# TODO: Update these paths to your data directory\n",
    "raster_dir = ''  # Directory containing your raster files\n",
    "points_file = ''  # Excel file with point coordinates and classes\n",
    "\n",
    "# Required data format:\n",
    "# - Points file (Excel): Must contain columns 'POINT_X', 'POINT_Y', 'class'\n",
    "# - Raster files: GeoTIFF format with same projection as points\n",
    "# - All rasters should cover the same geographic extent\n",
    "\n",
    "# Define your class/category mapping - customize based on your data\n",
    "class_type_mapping = {\n",
    "    '1': 'Class_1',    # Replace with your actual class names\n",
    "    '2': 'Class_2',    # e.g., 'Urban', 'Forest', 'Positive', 'Negative', etc.\n",
    "    '3': 'Class_3',\n",
    "    '4': 'Class_4',\n",
    "    '5': 'Class_5'\n",
    "    # Add or remove classes as needed for your specific problem\n",
    "}\n",
    "\n",
    "# Define raster files - customize based on your available data\n",
    "# Example:\n",
    "raster_files = {\n",
    "    'elevation': ['elevation.tif', 'elevation_1km.tif', 'elevation_5km.tif'],\n",
    "    'slope': ['slope.tif', 'slope_1km.tif', 'slope_5km.tif'],\n",
    "    'accessibility': ['walking_time.tif'],        # Optional: accessibility data\n",
    "    'hydrology': ['nearest_river_order.tif'],     # Optional: hydrological data\n",
    "    'land_cover': ['land_cover.tif'],             # Optional: land cover data\n",
    "    'soil_texture': ['soil_texture.tif']          # Optional: surface/texture data\n",
    "    # Add or remove variables based on your research needs\n",
    "    # Examples: precipitation, temperature, distance_to_roads, etc.\n",
    "}\n",
    "\n",
    "# Model parameters (adjust as needed)\n",
    "Z_THRESHOLD = 2.576  # For outlier removal (99% confidence)\n",
    "MIN_PRECISION_THRESHOLD = 0.65  # Minimum acceptable precision\n",
    "N_FOLDS = 5  # Number of cross-validation folds\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2748a48c",
   "metadata": {},
   "source": [
    "## 4. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a00ec76",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_raster_values(raster_path, points):\n",
    "    \"\"\"Extract raster values at given point locations\"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        values = [next(src.sample([(x, y)]))[0] for x, y in zip(points['POINT_X'], points['POINT_Y'])]\n",
    "    return np.array(values).flatten()\n",
    "\n",
    "def read_raster(raster_path):\n",
    "    \"\"\"Read entire raster data for prediction mapping\"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        data = src.read(1)\n",
    "        profile = src.profile\n",
    "    data = np.nan_to_num(data, nan=0)  # Replace NaNs with 0\n",
    "    return data.flatten(), profile\n",
    "\n",
    "def create_qq_plots(data, grid_size=(3, 5)):\n",
    "    \"\"\"Create Q-Q plots for data distribution analysis\"\"\"\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        n_plots = data.shape[1]\n",
    "    else:\n",
    "        n_plots = data.shape[1]\n",
    "\n",
    "    fig, axes = plt.subplots(grid_size[0], grid_size[1], figsize=(20, 15))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(min(n_plots, len(axes))):\n",
    "        ax = axes[i]\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            stats.probplot(data.iloc[:, i].dropna(), dist=\"norm\", plot=ax)\n",
    "            ax.set_title(f'Q-Q Plot: {data.columns[i]}')\n",
    "        else:\n",
    "            stats.probplot(data[:, i], dist=\"norm\", plot=ax)\n",
    "            ax.set_title(f'Q-Q Plot: Component {i + 1}')\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Remove empty subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def print_pca_loadings_and_weights(pca, data):\n",
    "    \"\"\"Analyze and visualize PCA loadings\"\"\"\n",
    "    loadings = pca.components_\n",
    "    loadings_df = pd.DataFrame(loadings.T, index=data.columns, \n",
    "                              columns=[f'PC{i+1}' for i in range(loadings.shape[0])])\n",
    "\n",
    "    print(\"Principal Component Loadings:\")\n",
    "    print(loadings_df.round(3))\n",
    "\n",
    "    # Visualize loadings\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(loadings_df, annot=True, cmap='coolwarm')\n",
    "    plt.title('Principal Component Loadings')\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate feature importance\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    feature_weights = loadings_df.copy()\n",
    "    \n",
    "    for i, ev in enumerate(explained_variance_ratio):\n",
    "        feature_weights.iloc[:, i] *= np.sqrt(ev)\n",
    "    \n",
    "    overall_feature_weights = feature_weights.sum(axis=1)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(overall_feature_weights)), overall_feature_weights.values)\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Overall Weight')\n",
    "    plt.title('Overall Weights of Original Features after PCA')\n",
    "    plt.xticks(range(len(overall_feature_weights)), overall_feature_weights.index, rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return loadings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db120d9",
   "metadata": {},
   "source": [
    "## 5. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015e6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load point data\n",
    "try:\n",
    "    points_data = pd.read_excel(points_file)\n",
    "    print(f\"Loaded {len(points_data)} points\")\n",
    "    print(f\"Columns: {list(points_data.columns)}\")\n",
    "    print(f\"Class distribution:\\n{points_data['class'].value_counts()}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Could not find points file at {points_file}\")\n",
    "    print(\"Please update the points_file path in the configuration section\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634d452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract raster values at point locations\n",
    "# TODO: Update these based on your actual raster files\n",
    "feature_data = {}\n",
    "raster_data_dict = {} # To store flattened full raster data for prediction\n",
    "main_profile = None # To store the profile of the first successfully loaded raster\n",
    "\n",
    "try:\n",
    "    first_raster_loaded = False\n",
    "    for feature_category, files_in_category in raster_files.items():\n",
    "        for file_name_in_config in files_in_category:\n",
    "            full_raster_path = os.path.join(raster_dir, file_name_in_config)\n",
    "            # Create a unique feature name, e.g., elevation_elevation or elevation_elevation_1km\n",
    "            # You might want a more sophisticated naming scheme if file_name_in_config can be complex\n",
    "            base_name = os.path.splitext(file_name_in_config)[0]\n",
    "            current_feature_name = f\"{feature_category}_{base_name}\" # Or simplify if redundant\n",
    "\n",
    "            if os.path.exists(full_raster_path):\n",
    "                print(f\"Processing: {current_feature_name} from {file_name_in_config}\")\n",
    "                # Extract values for points_data\n",
    "                feature_data[current_feature_name] = extract_raster_values(\n",
    "                    full_raster_path, points_data\n",
    "                )\n",
    "                # Read full raster for prediction map\n",
    "                flat_raster_array, profile = read_raster(full_raster_path)\n",
    "                raster_data_dict[current_feature_name] = flat_raster_array\n",
    "\n",
    "                if not first_raster_loaded and profile:\n",
    "                    main_profile = profile\n",
    "                    first_raster_loaded = True\n",
    "                elif first_raster_loaded and profile and \\\n",
    "                     (profile['height'] != main_profile['height'] or \\\n",
    "                      profile['width'] != main_profile['width']):\n",
    "                    print(f\"WARNING: Raster {file_name_in_config} has different dimensions than the first raster. This may cause issues.\")\n",
    "            else:\n",
    "                print(f\"WARNING: Raster file not found: {full_raster_path}\")\n",
    "\n",
    "    print(f\"Extracted {len(feature_data)} features for points.\")\n",
    "    print(f\"Loaded {len(raster_data_dict)} full raster layers for mapping.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or processing raster data: {e}\")\n",
    "    print(\"Please check your raster file paths and ensure files exist and are valid.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f09232a",
   "metadata": {},
   "source": [
    "## 6. Data Preprocessing and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32326fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature DataFrame\n",
    "if feature_data:\n",
    "    # Raw data\n",
    "    raw_data = pd.DataFrame(feature_data)\n",
    "    \n",
    "    print(\"Raw data statistics:\")\n",
    "    print(raw_data.describe())\n",
    "    \n",
    "    print(\"\\nSkewness of original data:\")\n",
    "    print(raw_data.skew())\n",
    "    \n",
    "    # Create Q-Q plots for raw data\n",
    "    create_qq_plots(raw_data)\n",
    "else:\n",
    "    print(\"No feature data loaded. Please check your file paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b818f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformations to normalize data\n",
    "# Customize these transformations based on your data distribution\n",
    "\n",
    "if feature_data:\n",
    "    # Example transformations - adjust based on your data\n",
    "    transformed_data = raw_data.copy()\n",
    "    \n",
    "    # Apply log transformation to skewed variables\n",
    "    for col in raw_data.columns:\n",
    "        if raw_data[col].skew() > 1:  # If highly skewed\n",
    "            transformed_data[col] = np.log1p(raw_data[col])  # log(1+x) transformation\n",
    "    \n",
    "    print(\"Skewness after transformation:\")\n",
    "    print(transformed_data.skew())\n",
    "    \n",
    "    # Create Q-Q plots for transformed data\n",
    "    create_qq_plots(transformed_data)\n",
    "    \n",
    "    # Apply same transformations to full raster data\n",
    "    raster_data = pd.DataFrame(raster_data_dict)\n",
    "    for col in transformed_data.columns:\n",
    "        if col in raster_data.columns and raw_data[col].skew() > 1:\n",
    "            raster_data[col] = np.log1p(raster_data[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e8e469",
   "metadata": {},
   "source": [
    "## 7. Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b87bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers using z-score threshold\n",
    "if 'transformed_data' in locals():\n",
    "    # Calculate z-scores\n",
    "    z_scores_data = np.abs(zscore(transformed_data))\n",
    "    z_scores_raster = np.abs(zscore(raster_data))\n",
    "    \n",
    "    # Create masks for valid data\n",
    "    mask_data = (z_scores_data < Z_THRESHOLD).all(axis=1)\n",
    "    mask_raster = (z_scores_raster < Z_THRESHOLD).all(axis=1)\n",
    "    \n",
    "    # Apply masks\n",
    "    data_cleaned = transformed_data[mask_data]\n",
    "    raster_data_cleaned = raster_data[mask_raster]\n",
    "    y_cleaned = points_data['class'][mask_data]\n",
    "    \n",
    "    print(f\"Original data shape: {transformed_data.shape}\")\n",
    "    print(f\"Data shape after cleaning: {data_cleaned.shape}\")\n",
    "    print(f\"Removed {len(transformed_data) - len(data_cleaned)} outliers ({(len(transformed_data) - len(data_cleaned))/len(transformed_data)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"No transformed data available for outlier removal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a725e3",
   "metadata": {},
   "source": [
    "## 8. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152678a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA analysis\n",
    "if 'data_cleaned' in locals():\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(data_cleaned)\n",
    "    \n",
    "    # Fit PCA\n",
    "    pca = PCA()\n",
    "    pca.fit(X_scaled)\n",
    "    \n",
    "    # Print explained variance\n",
    "    print(\"Explained variance ratio:\")\n",
    "    for i, var in enumerate(pca.explained_variance_ratio_):\n",
    "        print(f\"PC{i+1}: {var:.3f} ({var*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nCumulative explained variance:\")\n",
    "    cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "    for i, var in enumerate(cumsum):\n",
    "        print(f\"PC1-{i+1}: {var:.3f} ({var*100:.1f}%)\")\n",
    "    \n",
    "    # Analyze loadings\n",
    "    loadings_df = print_pca_loadings_and_weights(pca, data_cleaned)\n",
    "else:\n",
    "    print(\"No cleaned data available for PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8f4132",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Visualize PCA results\n",
    "if 'pca' in locals():\n",
    "    # Transform data to PC space\n",
    "    X_pca = pca.transform(X_scaled)\n",
    "    \n",
    "    # Plot PC1 vs PC2\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_cleaned, alpha=0.7, cmap='viridis')\n",
    "    plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)\")\n",
    "    plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)\")\n",
    "    plt.title(\"PCA: PC1 vs PC2 colored by class\")\n",
    "    plt.colorbar(scatter, label='Class')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot explained variance\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)\n",
    "    plt.xlabel('Principal Component')\n",
    "    plt.ylabel('Explained Variance Ratio')\n",
    "    plt.title('Explained Variance by Component')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, len(cumsum) + 1), cumsum, 'bo-')\n",
    "    plt.axhline(y=0.8, color='r', linestyle='--', label='80% variance')\n",
    "    plt.axhline(y=0.9, color='g', linestyle='--', label='90% variance')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Cumulative Explained Variance')\n",
    "    plt.title('Cumulative Explained Variance')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb7fdd0",
   "metadata": {},
   "source": [
    "## 9. Model Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa657fa",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate_model_with_kfold(X, y, model_class, pca_indices, model_params=None, k=5):\n",
    "    \"\"\"\n",
    "    Evaluate any model using K-Fold cross-validation\n",
    "    \"\"\"\n",
    "    if model_params is None:\n",
    "        model_params = {}\n",
    "    \n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=RANDOM_STATE)\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    best_recall = -1\n",
    "    best_model = None\n",
    "    best_scaler = None\n",
    "    best_pca = None\n",
    "    \n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        # Split data\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Scale data\n",
    "        fold_scaler = StandardScaler()\n",
    "        X_train_scaled = fold_scaler.fit_transform(X_train)\n",
    "        X_test_scaled = fold_scaler.transform(X_test)\n",
    "        \n",
    "        # Apply PCA\n",
    "        fold_pca = PCA(n_components=len(X.columns))\n",
    "        X_train_pca = fold_pca.fit_transform(X_train_scaled)\n",
    "        X_test_pca = fold_pca.transform(X_test_scaled)\n",
    "        \n",
    "        # Select components\n",
    "        X_train_selected = X_train_pca[:, pca_indices]\n",
    "        X_test_selected = X_test_pca[:, pca_indices]\n",
    "        \n",
    "        # Train model\n",
    "        model = model_class(**model_params)\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        \n",
    "        # Get probabilities\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_prob = model.predict_proba(X_test_selected)[:, 1]\n",
    "        else:\n",
    "            # For models without predict_proba, use decision function\n",
    "            y_prob = model.decision_function(X_test_selected)\n",
    "        \n",
    "        # Calculate precision-recall curve\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "        \n",
    "        # Find optimal threshold\n",
    "        optimal_idx = -1\n",
    "        max_recall = -1\n",
    "        \n",
    "        for idx in range(len(thresholds)):\n",
    "            if precision[idx] >= MIN_PRECISION_THRESHOLD:\n",
    "                if recall[idx] > max_recall:\n",
    "                    max_recall = recall[idx]\n",
    "                    optimal_idx = idx\n",
    "        \n",
    "        if optimal_idx == -1:\n",
    "            optimal_idx = np.argmax(precision[:-1])\n",
    "        \n",
    "        # Store best model\n",
    "        if recall[optimal_idx] > best_recall:\n",
    "            best_recall = recall[optimal_idx]\n",
    "            best_model = model\n",
    "            best_scaler = fold_scaler\n",
    "            best_pca = fold_pca\n",
    "        \n",
    "        # Calculate F1 score\n",
    "        f1 = 2 * (precision[optimal_idx] * recall[optimal_idx]) / (precision[optimal_idx] + recall[optimal_idx])\n",
    "        \n",
    "        precision_scores.append(precision[optimal_idx])\n",
    "        recall_scores.append(recall[optimal_idx])\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\"Fold {fold}: Precision={precision[optimal_idx]:.3f}, Recall={recall[optimal_idx]:.3f}, F1={f1:.3f}\")\n",
    "    \n",
    "    print(f\"\\nAverage - Precision: {np.mean(precision_scores):.3f}±{np.std(precision_scores):.3f}\")\n",
    "    print(f\"Average - Recall: {np.mean(recall_scores):.3f}±{np.std(recall_scores):.3f}\")\n",
    "    print(f\"Average - F1: {np.mean(f1_scores):.3f}±{np.std(f1_scores):.3f}\")\n",
    "    \n",
    "    return f1_scores, best_model, best_pca, best_scaler\n",
    "\n",
    "def plot_probability_map(probability_map, profile, name):\n",
    "    \"\"\"Plot and save probability map\"\"\"\n",
    "    # Create classification thresholds\n",
    "    mean_prob = np.mean(probability_map)\n",
    "    std_prob = np.std(probability_map)\n",
    "    \n",
    "    thresholds = [\n",
    "        mean_prob - std_prob,\n",
    "        mean_prob - 0.5 * std_prob,\n",
    "        mean_prob,\n",
    "        mean_prob + 0.5 * std_prob,\n",
    "        mean_prob + std_prob\n",
    "    ]\n",
    "    \n",
    "    # Classify probabilities\n",
    "    classified_map = np.zeros_like(probability_map, dtype=np.uint8)\n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        if i == 0:\n",
    "            classified_map[probability_map < threshold] = 1\n",
    "        else:\n",
    "            classified_map[(probability_map >= thresholds[i-1]) & (probability_map < threshold)] = i + 1\n",
    "    \n",
    "    classified_map[probability_map >= thresholds[-1]] = len(thresholds) + 1\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cmap = ListedColormap(['red', 'orange', 'yellow', 'lightgreen', 'green', 'darkgreen'])\n",
    "    plt.imshow(classified_map, cmap=cmap)\n",
    "    plt.title(f'Probability Map - {name}')\n",
    "    plt.colorbar(label='Probability Class')\n",
    "    plt.show()\n",
    "    \n",
    "    return classified_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc27588e",
   "metadata": {},
   "source": [
    "## 10. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eca0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different models with different PC combinations\n",
    "if 'data_cleaned' in locals() and 'y_cleaned' in locals():\n",
    "\n",
    "    models_to_test = {\n",
    "        'Random Forest': (RandomForestClassifier, {'n_estimators': 100, 'random_state': RANDOM_STATE}),\n",
    "        'Logistic Regression': (LogisticRegression, {'random_state': RANDOM_STATE, 'max_iter': 1000, 'solver': 'liblinear'}),\n",
    "        'K-Nearest Neighbors': (KNeighborsClassifier, {'n_neighbors': 5}),\n",
    "        'SVM': (SVC, {'probability': True, 'random_state': RANDOM_STATE}),\n",
    "        'XGBoost': (XGBClassifier, {'use_label_encoder': False, 'eval_metric': 'logloss', 'random_state': RANDOM_STATE})\n",
    "    }\n",
    "\n",
    "    # pc_combinations dictionary should be defined here as in your original notebook\n",
    "    # It is used by the updated map generation cell.\n",
    "    # Ensure this definition is robust, especially 'All PCs' if number of columns in data_cleaned changes.\n",
    "    # For example, if data_cleaned is available:\n",
    "    num_features = len(data_cleaned.columns) if 'data_cleaned' in locals() and hasattr(data_cleaned, 'columns') else 5 # Default to 5 if not available\n",
    "    \n",
    "    pc_combinations = {\n",
    "        'All PCs': list(range(num_features)), # Dynamically set based on features\n",
    "        'First 3 PCs': [i for i in [0, 1, 2] if i < num_features], # Ensure indices are valid\n",
    "        'First 5 PCs': [i for i in [0, 1, 2, 3, 4] if i < num_features],\n",
    "        # 'Top Variance PCs' might need to be defined after PCA analysis to know which PCs are top variance\n",
    "        # For now, let's assume it's similar to 'First 5 PCs' or a user-defined list based on their PCA inspection.\n",
    "        # Example: 'Top Variance PCs': [0, 1, 2, 3, 4] # User should adjust this based on their PCA results\n",
    "    }\n",
    "    # Ensure 'Top Variance PCs' or any other custom key used in evaluation is present in pc_combinations\n",
    "    # If 'Top Variance PCs' was intended to be dynamic, that logic would need to be implemented after PCA.\n",
    "    # For simplicity, if you had a specific set of indices for it:\n",
    "    # pc_combinations['Top Variance PCs'] = [0, 1, 3] # Example, ensure indices are < num_features\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for model_name, (model_class, model_params) in models_to_test.items():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Testing {model_name}\")\n",
    "        print('='*50)\n",
    "\n",
    "        model_results = {}\n",
    "\n",
    "        for pc_name, pc_indices_list_for_eval in pc_combinations.items():\n",
    "            # Ensure pc_indices_list_for_eval is not empty and all indices are valid for current data\n",
    "            valid_pc_indices_for_eval = [idx for idx in pc_indices_list_for_eval if idx < num_features]\n",
    "            if not valid_pc_indices_for_eval and pc_indices_list_for_eval: # If list was not empty but all indices were invalid\n",
    "                 print(f\"\\n--- {pc_name} --- SKIPPING: PC indices {pc_indices_list_for_eval} are out of bounds for {num_features} features.\")\n",
    "                 model_results[pc_name] = None\n",
    "                 continue\n",
    "            if not valid_pc_indices_for_eval and not pc_indices_list_for_eval and pc_name != 'All PCs': # If list was empty initially (and not 'All PCs' which implies all)\n",
    "                 print(f\"\\n--- {pc_name} --- SKIPPING: No PC indices defined.\")\n",
    "                 model_results[pc_name] = None\n",
    "                 continue\n",
    "\n",
    "\n",
    "            print(f\"\\n--- {pc_name} (using indices: {valid_pc_indices_for_eval}) ---\")\n",
    "            try:\n",
    "                f1_scores, best_model, best_pca_fold, best_scaler_fold = evaluate_model_with_kfold( # Renamed for clarity\n",
    "                    data_cleaned, y_cleaned, model_class, valid_pc_indices_for_eval, model_params, N_FOLDS\n",
    "                )\n",
    "                model_results[pc_name] = {\n",
    "                    'f1_scores': f1_scores,\n",
    "                    'mean_f1': np.mean(f1_scores),\n",
    "                    'std_f1': np.std(f1_scores),\n",
    "                    'best_model': best_model,\n",
    "                    'best_pca': best_pca_fold, # Storing the PCA object from the best fold\n",
    "                    'best_scaler': best_scaler_fold # Storing the Scaler object from the best fold\n",
    "                }\n",
    "            except Exception as e:\n",
    "                print(f\"Error with {model_name} - {pc_name}: {e}\")\n",
    "                model_results[pc_name] = None\n",
    "                # import traceback # Optional: for more detailed error for user\n",
    "                # traceback.print_exc()\n",
    "\n",
    "        results[model_name] = model_results\n",
    "else:\n",
    "    print(\"No cleaned data available for model comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eae30ef",
   "metadata": {},
   "source": [
    "## 11. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7d4dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison plots\n",
    "if 'results' in locals():\n",
    "    # Prepare data for plotting\n",
    "    plot_data = []\n",
    "    \n",
    "    for model_name, model_results in results.items():\n",
    "        for pc_name, result in model_results.items():\n",
    "            if result is not None:\n",
    "                for f1_score in result['f1_scores']:\n",
    "                    plot_data.append({\n",
    "                        'Model': model_name,\n",
    "                        'PC_Selection': pc_name,\n",
    "                        'F1_Score': f1_score\n",
    "                    })\n",
    "    \n",
    "    if plot_data:\n",
    "        df_results = pd.DataFrame(plot_data)\n",
    "        \n",
    "        # Box plot comparison\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        sns.boxplot(data=df_results, x='Model', y='F1_Score', hue='PC_Selection')\n",
    "        plt.title('Model Performance Comparison Across Different PC Selections')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend(title='PC Selection', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Summary statistics\n",
    "        summary_stats = df_results.groupby(['Model', 'PC_Selection'])['F1_Score'].agg(['mean', 'std']).round(3)\n",
    "        print(\"\\nSummary Statistics:\")\n",
    "        print(summary_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5276decf",
   "metadata": {},
   "source": [
    "## 12. Generate Prediction Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80ef2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate prediction maps for best performing models\n",
    "if 'results' in locals() and 'raster_data' in locals() and 'pc_combinations' in locals(): # Added 'pc_combinations' check\n",
    "    # Find best model overall\n",
    "    best_overall_f1 = 0\n",
    "    best_config = None\n",
    "    # To store the actual pc_indices list used by the best model\n",
    "    best_pc_indices_list = None\n",
    "\n",
    "    for model_name, model_results in results.items():\n",
    "        for pc_name, result in model_results.items():\n",
    "            if result is not None and result['mean_f1'] > best_overall_f1:\n",
    "                best_overall_f1 = result['mean_f1']\n",
    "                best_config = (model_name, pc_name, result)\n",
    "                # Store the pc_indices list that corresponds to this pc_name\n",
    "                if pc_name in pc_combinations:\n",
    "                    best_pc_indices_list = pc_combinations[pc_name]\n",
    "                else:\n",
    "                    # Fallback or error if pc_name isn't in pc_combinations,\n",
    "                    # though it should be if results were generated based on it.\n",
    "                    print(f\"Warning: PC selection name '{pc_name}' not found in 'pc_combinations' dict. Using default for map.\")\n",
    "                    # Define a default or handle error appropriately\n",
    "                    best_pc_indices_list = list(range(result['best_pca'].n_components_))\n",
    "\n",
    "\n",
    "    if best_config and best_pc_indices_list is not None:\n",
    "        model_name, pc_name, result = best_config\n",
    "        print(f\"Best model for map generation: {model_name} with {pc_name} (F1: {best_overall_f1:.3f})\")\n",
    "        print(f\"Using PC indices for map: {best_pc_indices_list}\")\n",
    "\n",
    "        # Generate prediction map\n",
    "        try:\n",
    "            # Ensure raster_data has the same columns as the data used for training the scaler/pca\n",
    "            # This alignment should ideally happen when raster_data (DataFrame) is first created/transformed.\n",
    "            # Assuming 'data_cleaned.columns' represents the feature set the 'best_scaler' and 'best_pca' were trained on.\n",
    "            if 'data_cleaned' in locals():\n",
    "                 # Ensure column order and presence matches data_cleaned for the scaler\n",
    "                raster_data_for_map = raster_data[data_cleaned.columns]\n",
    "            else:\n",
    "                print(\"Warning: 'data_cleaned' not found. Assuming 'raster_data' columns are already aligned for the scaler.\")\n",
    "                raster_data_for_map = raster_data\n",
    "\n",
    "\n",
    "            # Scale raster data using the scaler from the best fold of the best model\n",
    "            raster_scaled = result['best_scaler'].transform(raster_data_for_map)\n",
    "            # Apply PCA transformation using the PCA object from the best fold\n",
    "            raster_pca = result['best_pca'].transform(raster_scaled)\n",
    "\n",
    "            # Select the appropriate principal components using the dynamically retrieved list\n",
    "            # Ensure selected indices are within the bounds of available PCs from this specific PCA object\n",
    "            valid_pc_indices_for_map = [idx for idx in best_pc_indices_list if idx < result['best_pca'].n_components_]\n",
    "            if len(valid_pc_indices_for_map) != len(best_pc_indices_list):\n",
    "                print(f\"Warning: Some specified PC indices for mapping ({best_pc_indices_list}) were out of bounds for the {result['best_pca'].n_components_} PCs available from the best model's PCA. Using valid subset: {valid_pc_indices_for_map}\")\n",
    "            \n",
    "            if not valid_pc_indices_for_map:\n",
    "                print(f\"Error: No valid PC indices to select for map generation with {pc_name}. Skipping map.\")\n",
    "            else:\n",
    "                raster_selected = raster_pca[:, valid_pc_indices_for_map]\n",
    "\n",
    "                # Predict probabilities\n",
    "                if hasattr(result['best_model'], 'predict_proba'):\n",
    "                    probabilities = result['best_model'].predict_proba(raster_selected)[:, 1]\n",
    "                else: # For models like SVC without probability=True initially, or other decision_function based models\n",
    "                    probabilities = result['best_model'].decision_function(raster_selected)\n",
    "                    # Normalize to 0-1 range if it's not already a probability\n",
    "                    if not (probabilities.min() >= 0 and probabilities.max() <= 1): # Basic check\n",
    "                        probabilities = (probabilities - probabilities.min()) / (probabilities.max() - probabilities.min() + 1e-9) # add epsilon\n",
    "\n",
    "                # Reshape to map\n",
    "                if main_profile:\n",
    "                    height, width = main_profile['height'], main_profile['width']\n",
    "                    if probabilities.size == height * width:\n",
    "                        probability_map = probabilities.reshape(height, width)\n",
    "\n",
    "                        # Plot map\n",
    "                        classified_map = plot_probability_map(probability_map, main_profile, f\"{model_name}_{pc_name.replace(' ', '_')}\")\n",
    "\n",
    "                        print(f\"Prediction map generated successfully!\")\n",
    "                        print(f\"Map statistics - Mean: {np.mean(probability_map):.3f}, Std: {np.std(probability_map):.3f}\")\n",
    "                    else:\n",
    "                        print(f\"Error: Probability array size ({probabilities.size}) does not match map dimensions ({height*width}). Cannot reshape.\")\n",
    "                else:\n",
    "                    print(\"Error: main_profile not available. Cannot determine map dimensions.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating prediction map for {model_name} with {pc_name}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc() # Print full traceback for debugging\n",
    "    elif not 'raster_data' in locals():\n",
    "        print(\"Skipping map generation: 'raster_data' is not defined.\")\n",
    "    elif not 'pc_combinations' in locals():\n",
    "        print(\"Skipping map generation: 'pc_combinations' is not defined (needed to get PC indices).\")\n",
    "    else:\n",
    "        print(\"Skipping map generation: No best model configuration found or PC indices missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f4d86a",
   "metadata": {},
   "source": [
    "## 13. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98588442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of results\n",
    "if 'results' in locals():\n",
    "    print(\"=\"*60)\n",
    "    print(\"SUMMARY OF RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for model_name, model_results in results.items():\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        for pc_name, result in model_results.items():\n",
    "            if result is not None:\n",
    "                print(f\"  {pc_name}: F1 = {result['mean_f1']:.3f} ± {result['std_f1']:.3f}\")\n",
    "            else:\n",
    "                print(f\"  {pc_name}: Failed\")\n",
    "    \n",
    "    print(f\"\\nBest Overall Performance:\")\n",
    "    if best_config:\n",
    "        print(f\"  Model: {best_config[0]}\")\n",
    "        print(f\"  PC Selection: {best_config[1]}\")\n",
    "        print(f\"  F1 Score: {best_config[2]['mean_f1']:.3f} ± {best_config[2]['std_f1']:.3f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Analysis complete! Check the prediction maps above.\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"No results to summarize. Please check your data and configuration.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
