# -*- coding: utf-8 -*-
"""model_10/20_PCA

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10bmmTOARee_51fsRnUbbKZlPFzu3RMu8
"""

pip install rasterio

#Process the data and display their distribution
import pandas as pd
import os
import rasterio
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Load the points data
raster_dir = '/content/drive/MyDrive/model_raster/' #replace with your own directory of data, those data can be found under Model & Input/Input_variable_rasters in the Google Drive,
points_file = os.path.join(raster_dir, 'Input_points_of_both_classes_7.17.xlsx')
points_data = pd.read_excel(points_file)

# Define a mapping for human-readable soil type names
# For input points, they only cover 4 types of soils, so the actual graphs don't contain all of them following types
soil_type_mapping = {
    '1': 'Lithosols',
    '2': 'Regosols',
    '3': 'Solonchaks',
    '4': 'Xerosols',
    '5': 'Gleysols',
    '6': 'Yermosols',
    '7': 'Fluvisols',
    '8': 'Kastanozems',
    '9': 'Cambisols',
    '10': 'Chernozems',
    '11': 'Solonetz'
}


# Function to extract raster values at given points
def extract_raster_values(raster_path, points):
    with rasterio.open(raster_path) as src:
        values = [next(src.sample([(x, y)]))[0] for x, y in zip(points['POINT_X'], points['POINT_Y'])]
    return np.array(values).flatten()

# Define raster files for different buffers and soil types
raster_files = {
    'elevation': ['elevation.tif', 'elevation_1km.tif','elevation_5km.tif', 'elevation_10km.tif', 'elevation_15km.tif'],
    'slope': ['slope.tif', 'slope_1km.tif', 'slope_5km.tif', 'slope_10km.tif', 'slope_15km.tif'],
    'walking_time': ['walking_time.tif'],
    'river_order': ['nearest_river_stream_order.tif'],
    'main_soil_type': ['main_soil_type.tif'],
    'associated_soil_type': ['associated_soil_type.tif'],
    'soil_texture': ['soil_texture.tif']
}

# Function to rename columns based on the mapping
def rename_columns(column_names, prefix):
    new_column_names = []
    for col in column_names:
        col_suffix = col.split('_')[-1]
        new_name = f"{prefix}_{soil_type_mapping.get(col_suffix, col_suffix)}"
        new_column_names.append(new_name)
    return new_column_names

# Function to print PCA loadings and overall feature weights
def print_pca_loadings_and_weights(pca, data):
    # Get the loadings (components)
    loadings = pca.components_

    # Create a DataFrame for easy interpretation
    loadings_df = pd.DataFrame(loadings.T, index=data.columns, columns=[f'PC{i+1}' for i in range(loadings.shape[0])])

    # Print the loadings
    print("Principal Component Loadings:")
    print(loadings_df)

    # Visualize the loadings
    plt.figure(figsize=(12, 8))
    sns.heatmap(loadings_df, annot=True, cmap='coolwarm')
    plt.title('Principal Component Loadings')
    plt.show()

    # Define the explained variance ratio
    explained_variance_ratio = pca.explained_variance_ratio_

    # Create a copy of the DataFrame to hold the feature weights
    feature_weights = loadings_df.copy()

    # Multiply each loading by the square root of the explained variance ratio
    for i, ev in enumerate(explained_variance_ratio):
        feature_weights.iloc[:, i] *= np.sqrt(ev)

    # Sum the contributions across all principal components to get the overall weight of each feature
    overall_feature_weights = feature_weights.sum(axis=1)

    # Create a DataFrame to display the overall weights with feature names
    overall_feature_weights_df = pd.DataFrame({
        'Feature': loadings_df.index,
        'Overall Weight': overall_feature_weights
    })

    # Print the DataFrame
    print(overall_feature_weights_df)

    # Plot the overall weights of features
    plt.figure(figsize=(10, 6))
    plt.bar(overall_feature_weights_df['Feature'], overall_feature_weights_df['Overall Weight'])
    plt.xlabel('Features')
    plt.ylabel('Overall Weight')
    plt.title('Overall Weights of Original Features after PCA Transformation')
    plt.show()

# Function to extract raster values at given points
def extract_raster_values_at_points(raster_path, points):
    with rasterio.open(raster_path) as src:
        values = [next(src.sample([(x, y)]))[0] for x, y in zip(points['POINT_X'], points['POINT_Y'])]
    return np.array(values).flatten()

# Function to read raster data
def read_raster(raster_path):
    with rasterio.open(raster_path) as src:
        data = src.read(1)
        profile = src.profile
    data = np.nan_to_num(data, nan=0)  # Replace NaNs with 0
    return data.flatten(), profile

def create_qq_plots(data, grid_size=(3, 5)):
    """
    Create Q-Q plots for each column in a DataFrame or each principal component in an array.

    Parameters:
    - data: DataFrame or NumPy array containing the data to plot.
    - grid_size: Tuple indicating the number of rows and columns in the subplot grid (optional).
    """
    data = data.drop(columns= ['texture_values'])
    # Check if the input data is a DataFrame
    if isinstance(data, pd.DataFrame):
        n_plots = data.shape[1]  # Number of plots based on the number of columns in the DataFrame
    else:
        n_plots = data.shape[1]  # Number of plots based on the number of components in PCA output

    # Create subplots
    fig, axes = plt.subplots(grid_size[0], grid_size[1], figsize=(20, 15))
    axes = axes.flatten()

    # Loop through each variable/component and plot its Q-Q plot in a subplot
    for i in range(n_plots):
        ax = axes[i]  # Select the axis for the subplot
        if isinstance(data, pd.DataFrame):
            stats.probplot(data.iloc[:, i].dropna(), dist="norm", plot=ax)  # For DataFrame
            ax.set_title(f'Q-Q Plot: {data.columns[i]}')
        else:
            stats.probplot(data[:, i], dist="norm", plot=ax)  # For PCA components
            ax.set_title(f'Q-Q Plot: Component {i + 1}')
        ax.grid(True)

    # Remove any empty subplots (if the number of variables is less than the grid size)
    for j in range(i + 1, len(axes)):
        fig.delaxes(axes[j])

    # Adjust layout and display the figure
    plt.tight_layout()
    plt.show()
# Define the target variable
y = points_data['class']

from math import e
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier


elevation_original = extract_raster_values(os.path.join(raster_dir, 'elevation.tif'), points_data)
elevation_1km = extract_raster_values(os.path.join(raster_dir, 'elevation_1km.tif'), points_data)
elevation_5km = extract_raster_values(os.path.join(raster_dir, 'elevation_5km.tif'), points_data)
elevation_10km = extract_raster_values(os.path.join(raster_dir, 'elevation_10km.tif'), points_data)
elevation_15km = extract_raster_values(os.path.join(raster_dir, 'elevation_15km.tif'), points_data)
slope_original = extract_raster_values(os.path.join(raster_dir, 'slope.tif'), points_data)
slope_1km = extract_raster_values(os.path.join(raster_dir, 'slope_1km.tif'), points_data)
slope_5km = extract_raster_values(os.path.join(raster_dir, 'slope_5km.tif'), points_data)
slope_10km = extract_raster_values(os.path.join(raster_dir, 'slope_10km.tif'), points_data)
slope_15km = extract_raster_values(os.path.join(raster_dir, 'slope_15km.tif'), points_data)
walking_time_values = extract_raster_values(os.path.join(raster_dir, raster_files['walking_time'][0]), points_data)
river_order_values = extract_raster_values(os.path.join(raster_dir, raster_files['river_order'][0]), points_data)
texture_values = extract_raster_values(os.path.join(raster_dir, raster_files['soil_texture'][0]), points_data)



elevation_original_raster, profile = read_raster(os.path.join(raster_dir, 'elevation.tif'))
elevation_1km_raster,_ = read_raster(os.path.join(raster_dir, 'elevation_1km.tif'))
elevation_5km_raster,_ = read_raster(os.path.join(raster_dir, 'elevation_5km.tif'))
elevation_10km_raster,_ = read_raster(os.path.join(raster_dir, 'elevation_10km.tif'))
elevation_15km_raster,_ = read_raster(os.path.join(raster_dir, 'elevation_15km.tif'))
slope_original_raster,_ = read_raster(os.path.join(raster_dir, 'slope.tif'))
slope_1km_raster,_ = read_raster(os.path.join(raster_dir, 'slope_1km.tif'))
slope_5km_raster,_ = read_raster(os.path.join(raster_dir, 'slope_5km.tif'))
slope_10km_raster,_ = read_raster(os.path.join(raster_dir, 'slope_10km.tif'))
slope_15km_raster,_ = read_raster(os.path.join(raster_dir, 'slope_15km.tif'))
walking_time_values_raster,_ = read_raster(os.path.join(raster_dir, 'walking_time.tif'))
river_order_values_raster,_ = read_raster(os.path.join(raster_dir, 'nearest_river_stream_order.tif'))
texture_values_raster,_ = read_raster(os.path.join(raster_dir, 'soil_texture.tif'))

transform = profile['transform']

# @title
from scipy import stats
raw_data = pd.DataFrame({
    'elevation_original': elevation_original,
    'elevation_1km': elevation_1km,
    'elevation_5km': elevation_5km,
    'elevation_10km': elevation_10km,
    'elevation_15km': elevation_15km,
    'slope_original': slope_original,
    'slope_1km': slope_1km,
    'slope_5km': slope_5km,
    'slope_10km': slope_10km,
    'slope_15km': slope_15km,
    'walking_time_values': walking_time_values,
    'river_order_values': river_order_values,
    'texture_values': texture_values
})
skewness = raw_data.skew()
print("Skewness of original data:")
print(skewness)
create_qq_plots(raw_data)
data = pd.DataFrame({
    'elevation_original': np.log1p(elevation_original),
    'elevation_1km': np.log1p(elevation_1km),
    'elevation_5km': np.log1p(elevation_5km),
    'elevation_10km': elevation_10km,
    'elevation_15km': elevation_15km,
    'slope_original': np.log1p(slope_original),
    'slope_1km': np.log1p(slope_1km),
    'slope_5km': slope_5km,
    'slope_10km': slope_10km,
    'slope_15km': slope_15km,
    'walking_time_values': np.log1p(walking_time_values),
    'river_order_values': river_order_values,
    'texture_values': texture_values
})
skewness = data.skew()
print("Skewness of transformed data:")
print(skewness)
#plot q-q plot for normalized data
create_qq_plots(data)

assert len(elevation_original_raster) == len(elevation_1km_raster) == len(walking_time_values_raster)
raster_data = pd.DataFrame({
    'elevation_original': np.log1p(elevation_original_raster),
    'elevation_1km': np.log1p(elevation_1km_raster),
    'elevation_5km': np.log1p(elevation_5km_raster),
    'elevation_10km': elevation_10km_raster,
    'elevation_15km': elevation_15km_raster,
    'slope_original': np.log1p(slope_original_raster),
    'slope_1km': np.log1p(slope_1km_raster),
    'slope_5km': slope_5km_raster,
    'slope_10km': slope_10km_raster,
    'slope_15km': slope_15km_raster,
    'walking_time_values': np.log1p(walking_time_values_raster),
    'river_order_values': river_order_values_raster,
    'texture_values': texture_values_raster
})

# Define the target variable
y = points_data['class']
#plot the distirbution of data

"""**Log-Transformed Data before Removal**

Data Removal (99%)
"""

# @title
from scipy.stats import zscore
# Define the z-score threshold
z_threshold = 2.576

# Calculate z-scores for both data and raster_data
z_scores_data = np.abs(zscore(data))
z_scores_raster = np.abs(zscore(raster_data))

# Create a mask for valid rows based on z-score threshold
mask_data = (z_scores_data < z_threshold).all(axis=1)
mask_raster = (z_scores_raster < z_threshold).all(axis=1)

# Apply the mask to remove outliers
data_cleaned = data[mask_data]
raster_data_cleaned = raster_data[mask_raster]
y_cleaned = y[mask_data]
print(data_cleaned.shape)
print(y_cleaned.shape)
print(type(data_cleaned))
print(type(y_cleaned))
#create the q-q plot

#Plot the PCA loadings using the removed data
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(data_cleaned)
pca = PCA()
pca.fit(X_train_scaled)
print_pca_loadings_and_weights(pca, data_cleaned)
#print the loadings of the pca

# Transform data into principal component space
X_pca = pca.transform(X_train_scaled)

# Plot PC1 vs PC2
plt.figure(figsize=(8, 6))
plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.7)
plt.xlabel("Principal Component 1")
plt.ylabel("Principal Component 2")
plt.title("PCA: PC1 vs PC2")
plt.axhline(y=0, color='gray', linestyle='--', linewidth=0.7)
plt.axvline(x=0, color='gray', linestyle='--', linewidth=0.7)
plt.grid(True, linestyle='--', alpha=0.5)
plt.show()

loadings = pca.components_.T  # Transpose to align with features
columns = [f"PC{i+1}" for i in range(loadings.shape[1])]

# Create a DataFrame
loadings_df = pd.DataFrame(loadings, index=data_cleaned.columns, columns=columns)

# Round to 3 decimals
loadings_df = loadings_df.round(3)

# Display the table
print(loadings_df)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import KFold
from sklearn.metrics import roc_curve, auc, precision_recall_curve
from imblearn.over_sampling import SMOTE
from sklearn.base import clone
from matplotlib.colors import ListedColormap

def evaluate_model_with_kfold(X, y, k, pca_indices, n_estimators=1000, random_state=42):
    """
    Evaluate a Random Forest model using K-Fold cross-validation and return the best model.
    """
    kf = KFold(n_splits=k, shuffle=True, random_state=42)
    precision_scores = []
    recall_scores = []
    f1_scores = []
    scaler = StandardScaler()
    min_precision_threshold = 0.65

    # Track best model
    best_recall = -1
    best_precision = -1
    best_model = None
    best_pca = None
    best_scaler = None

    # Create a figure for all PR curves
    plt.figure(figsize=(15, 10))

    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):
        # Split and prepare data
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        pca = PCA(n_components=13)
        X_train_pca = pca.fit_transform(X_train_scaled)
        X_test_pca = pca.transform(X_test_scaled)

        X_train_pca_selected = X_train_pca[:, pca_indices]
        X_test_pca_selected = X_test_pca[:, pca_indices]

        fold_model = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)
        fold_model.fit(X_train_pca_selected, y_train)

        y_prob = fold_model.predict_proba(X_test_pca_selected)[:, 1]

        precision, recall, thresholds = precision_recall_curve(y_test, y_prob)
        auc_score = auc(recall, precision)

        # Plot PR curve for this fold
        plt.plot(recall, precision, lw=2, label=f'Fold {fold} (AUC = {auc_score:.2f})')

        optimal_idx = -1
        max_recall = -1
        curr_max_precision_idx = np.argmax(precision[:-1])

        for idx in range(len(thresholds)):
            if precision[idx] >= min_precision_threshold:
                if recall[idx] > max_recall:
                    max_recall = recall[idx]
                    optimal_idx = idx

        if optimal_idx == -1:
            optimal_idx = curr_max_precision_idx
            print(f"Fold {fold}: Using highest precision available: {precision[optimal_idx]:.4f}, Recall: {recall[optimal_idx]:.4f}")
        else:
            print(f"Fold {fold}: Found precision ≥ 0.65: {precision[optimal_idx]:.4f}, Recall: {recall[optimal_idx]:.4f}")
            if recall[optimal_idx] > best_recall:
                best_recall = recall[optimal_idx]
                best_precision = precision[optimal_idx]
                best_model = fold_model
                best_pca = pca
                best_scaler = scaler

        # Plot optimal point for this fold
        plt.plot(recall[optimal_idx], precision[optimal_idx], 'ro')

        f1_score = 2 * (precision[optimal_idx] * recall[optimal_idx]) / (precision[optimal_idx] + recall[optimal_idx])
        precision_scores.append(precision[optimal_idx])
        recall_scores.append(recall[optimal_idx])
        f1_scores.append(f1_score)

    # Finalize PR curve plot
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curves for All Folds')
    plt.grid(True)
    plt.plot([0, 1], [min_precision_threshold, min_precision_threshold], 'k--', label='Minimum Precision Threshold')
    plt.legend(loc='lower left')
    plt.show()

    print(f"\nAverage Precision: {np.mean(precision_scores):.3f} ± {np.std(precision_scores):.3f}")
    print(f"Average Recall: {np.mean(recall_scores):.3f} ± {np.std(recall_scores):.3f}")
    print(f"Average F1 Score: {np.mean(f1_scores):.3f} ± {np.std(f1_scores):.3f}")
    print(f"\nBest Model - Precision: {best_precision:.3f}, Recall: {best_recall:.3f}")

    return f1_scores, best_model, best_pca, best_scaler

def plot_raster_map(mean_prob, std_dev_prob, probability_map, name):
    cmap = ListedColormap(['red', 'orange', 'yellow', 'lightgreen', 'green'])

    # Define thresholds using mean and standard deviation
    low_threshold = mean_prob - std_dev_prob
    moderate_low_threshold = mean_prob - 0.5 * std_dev_prob
    moderate_threshold = mean_prob
    moderate_high_threshold = mean_prob + 0.5 * std_dev_prob
    high_threshold = mean_prob + 1 * std_dev_prob

    # Create an empty array for the classified map
    classified_map = np.zeros(probability_map.shape, dtype=np.uint8)
    # Assign classes based on the defined thresholds
    classified_map[(probability_map >= 0) & (probability_map < low_threshold)] = 1      # Low Probability
    classified_map[(probability_map >= low_threshold) & (probability_map < moderate_threshold)] = 2  # Moderate-Low Probability
    classified_map[(probability_map >= moderate_threshold) & (probability_map < high_threshold)] = 3  # Moderate Probability
    classified_map[(probability_map >= moderate_high_threshold) & (probability_map < high_threshold)] = 4  # Moderate-High Probability
    classified_map[(probability_map >= high_threshold) & (probability_map <= 1.0)] = 5  # High Probability


    output_raster_path = f'predicted_probability_map_{name}.tif'

    with rasterio.open(
        output_raster_path,
        'w',
        driver='GTiff',
        height=classified_map.shape[0],
        width=classified_map.shape[1],
        count=1,
        dtype='uint8',
        crs=profile['crs'],
        transform=profile['transform'],
    ) as dst:
        dst.write(classified_map, 1)

    # Plot the classified map
    plt.figure(figsize=(10, 8))
    plt.imshow(classified_map, cmap=cmap, vmin=1, vmax=5)
    plt.title(f'Classified Probability Map - {name.capitalize()} PCs')
    plt.colorbar(ticks=[1, 2, 3, 4, 5],
                label='Classes',
                format='%d')

    plt.show()

    return classified_map, output_raster_path

"""With all PCs:"""

pca_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
accuracies_all, rf_model_all, pca_all, scaler = evaluate_model_with_kfold(
    data_cleaned, y_cleaned, 5, pca_indices
)
print(accuracies_all)


raster_data_scaled = scaler.transform(raster_data)
raster_data_pca = pca_all.transform(raster_data_scaled)

# Predict probabilities using the best model
probability_map = rf_model_all.predict_proba(raster_data_pca)[:, 1]

# Reshape the probabilities to the original raster shape
height, width = profile['height'], profile['width']
probability_map = probability_map.reshape(height, width)
mean_prob = np.mean(probability_map)
std_dev_prob = np.std(probability_map)

plot_raster_map(mean_prob, std_dev_prob, probability_map, 'all')

"""**First 5 PCs**"""

pca_indices = [0, 1, 2, 3, 4]
accuracies_5, rf_5, pca_5, scaler = evaluate_model_with_kfold(
    data_cleaned, y_cleaned, 5, pca_indices
)
print(accuracies_5)

# @title
from matplotlib.colors import ListedColormap
from matplotlib.colors import LinearSegmentedColormap
raster_data_scaled = scaler.transform(raster_data)
raster_data_pca = pca_5.transform(raster_data_scaled)[:, 0:5]

# Predict probabilities using the best model
probability_map = rf_5.predict_proba(raster_data_pca)[:, 1]

# Reshape the probabilities to the original raster shape
height, width = profile['height'], profile['width']
probability_map = probability_map.reshape(height, width)

mean_prob = np.mean(probability_map)
std_dev_prob = np.std(probability_map)

plot_raster_map(mean_prob, std_dev_prob, probability_map, 'first5')

"""First 7"""

# @title
pca_indices = [0, 1, 2, 3, 4, 5, 6]
accuracies_7, rf_7, pca_7, scaler = evaluate_model_with_kfold(
    data_cleaned, y_cleaned, 5, pca_indices
)

# @title
from matplotlib.colors import LinearSegmentedColormap
raster_data_scaled = scaler.transform(raster_data)
raster_data_pca = pca_7.transform(raster_data_scaled)[:, 0:7]

# Predict probabilities using the best model
probability_map = rf_7.predict_proba(raster_data_pca)[:, 1]

# Reshape the probabilities to the original raster shape
height, width = profile['height'], profile['width']
probability_map = probability_map.reshape(height, width)

mean_prob = np.mean(probability_map)
std_dev_prob = np.std(probability_map)

plot_raster_map(mean_prob, std_dev_prob, probability_map, 'first7')

"""Last 8 PCS"""

# @title

pca_indices = [5, 6, 7, 8, 9, 10, 11, 12]

accuracies_last8, rf_8, pca_last8, scaler = evaluate_model_with_kfold(
    data_cleaned, y_cleaned, 5, pca_indices
)

# @title
from matplotlib.colors import LinearSegmentedColormap
raster_data_scaled = scaler.transform(raster_data)
raster_data_pca =  pca_last8.transform(raster_data_scaled)[:, 5:]


# Predict probabilities using the best model
probability_map = rf_8.predict_proba(raster_data_pca)[:, 1]


# Reshape the probabilities to the original raster shape
height, width = profile['height'], profile['width']
probability_map = probability_map.reshape(height, width)

mean_prob = np.mean(probability_map)
std_dev_prob = np.std(probability_map)

plot_raster_map(mean_prob, std_dev_prob, probability_map, 'last8')

"""**Last 9(5-12) PCs**"""

# @title

pca_indices = [4, 5, 6, 7, 8, 9, 10, 11, 12]

accuracies_last9, rf_9, pca_last9, scaler = evaluate_model_with_kfold(
    data_cleaned, y_cleaned, 5, pca_indices
)

# @title
raster_data_scaled = scaler.transform(raster_data)
raster_data_pca = pca_last9.transform(raster_data_scaled)[:, 4:]

# Predict probabilities using the best model
probability_map = rf_9.predict_proba(raster_data_pca)[:, 1]

# Reshape the probabilities to the original raster shape
height, width = profile['height'], profile['width']
probability_map = probability_map.reshape(height, width)

mean_prob = np.mean(probability_map)
std_dev_prob = np.std(probability_map)

plot_raster_map(mean_prob, std_dev_prob, probability_map, 'last9')

"""**Kvamme, with PC > abs(0.51)** - PC 5,6,7,9,10,12,13"""

# @title
pca_indices = [4, 5, 6, 8, 9, 10, 11, 12]
accuracies_k, rf_k, pca_k, scaler = evaluate_model_with_kfold(
    data_cleaned, y_cleaned, 5, pca_indices
)
print(accuracies_k)


raster_data_scaled = scaler.transform(raster_data)
raster_data_pca = pca_k.transform(raster_data_scaled)[:, pca_indices]

# Predict probabilities using the best model
probability_map = rf_k.predict_proba(raster_data_pca)[:, 1]

# Reshape the probabilities to the original raster shape
height, width = profile['height'], profile['width']
probability_map = probability_map.reshape(height, width)

mean_prob = np.mean(probability_map)
std_dev_prob = np.std(probability_map)

plot_raster_map(mean_prob, std_dev_prob, probability_map, 'Kvamme')

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import cross_val_score, KFold
# Define the models in a list for easier iteration
# Combine all accuracies into a single DataFrame for seaborn
print(accuracies_all)
print(accuracies_5)
print(accuracies_last9)
print(accuracies_last8)
print(accuracies_k)


flattened_accuracies_all = accuracies_all
flattened_accuracies_5 = accuracies_5

flattened_accuracies_7 = accuracies_7
flattened_accuracies_last9 = accuracies_last9
flattened_accuracies_last8 = accuracies_last8

# Check if accuracies_k is already flattened
if isinstance(accuracies_k[0], list):
    flattened_accuracies_k = [item for sublist in accuracies_k for item in sublist]  # Flatten if it's a list of lists
else:
    flattened_accuracies_k = accuracies_k # Otherwise, assume it's already flattened
# Combine all accuracies into a single DataFrame for seaborn
plot_data = {
    'F1-Score': (
        flattened_accuracies_all +
        flattened_accuracies_5 +
        flattened_accuracies_7 +
        flattened_accuracies_last9 +
        flattened_accuracies_last8 +
        flattened_accuracies_k
    ),
    'PCA Selection': (
        ['All PCs'] * len(flattened_accuracies_all) +
        ['First 5 PCs'] * len(flattened_accuracies_5) +
        ['First 7 PCs'] * len(flattened_accuracies_7) +
        ['Last 8 PCs'] * len(flattened_accuracies_last8) +
        ['Last 9 PCs'] * len(flattened_accuracies_last9) +
        ['Kvamme'] * len(flattened_accuracies_k)
    )
}
# Create a DataFrame
accuracy_df = pd.DataFrame(plot_data)

accuracy_df['F1-Score'] = pd.to_numeric(accuracy_df['F1-Score'])

# Calculate and print statistics for each PCA selection
stats = accuracy_df.groupby('PCA Selection')['F1-Score'].agg(['mean', 'median', 'std', 'min', 'max'])
print(stats)

# Set up the matplotlib figure
plt.figure(figsize=(12, 6))

# Create a boxplot
sns.boxplot(x='PCA Selection', y='F1-Score', data=accuracy_df)

# Set plot title and labels
plt.title('Distribution of F1-Score by PCA Selection', fontsize=16)
plt.xlabel('PCA Selection', fontsize=14)
plt.ylabel('F1-Score', fontsize=14)

# Show the plot
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

"""**Logistic Regression**"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_recall_curve

def evaluate_logistic_regression(X, y, raster_data=None, profile=None):
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    precision_scores = []
    recall_scores = []
    f1_scores = []
    scaler = StandardScaler()
    min_precision_threshold = 0.65

    # Track best model
    best_recall = -1
    best_precision = -1
    best_model = None
    best_fold_data = None

    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):
        # Split and prepare data
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # Scale the data
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # Perform PCA
        pca = PCA(n_components=13)
        X_train_pca = pca.fit_transform(X_train_scaled)
        X_test_pca = pca.transform(X_test_scaled)

        # Train model
        fold_model = LogisticRegression(max_iter=1000, random_state=42)
        fold_model.fit(X_train_pca, y_train)

        # Get probabilities
        y_prob = fold_model.predict_proba(X_test_pca)[:, 1]

        # Calculate precision-recall curve
        precision, recall, thresholds = precision_recall_curve(y_test, y_prob)

        # Find optimal threshold
        optimal_idx = -1
        max_recall = -1
        curr_max_precision_idx = np.argmax(precision[:-1])

        for idx in range(len(thresholds)):
            if precision[idx] >= min_precision_threshold:
                if recall[idx] > max_recall:
                    max_recall = recall[idx]
                    optimal_idx = idx

        if optimal_idx == -1:
            optimal_idx = curr_max_precision_idx
            print(f"Fold {fold}: Using highest precision available: {precision[optimal_idx]:.4f}, Recall: {recall[optimal_idx]:.4f}")
        else:
            print(f"Fold {fold}: Found precision ≥ 0.65: {precision[optimal_idx]:.4f}, Recall: {recall[optimal_idx]:.4f}")
            if recall[optimal_idx] > best_recall:
                best_recall = recall[optimal_idx]
                best_precision = precision[optimal_idx]
                best_model = fold_model
                best_fold_data = (scaler, pca)  # Save the scaler and PCA from best fold

        f1_score = 2 * (precision[optimal_idx] * recall[optimal_idx]) / (precision[optimal_idx] + recall[optimal_idx])
        precision_scores.append(precision[optimal_idx])
        recall_scores.append(recall[optimal_idx])
        f1_scores.append(f1_score)

    print(f"\nAverage Precision: {np.mean(precision_scores):.4f} (±{np.std(precision_scores):.4f})")
    print(f"Average Recall: {np.mean(recall_scores):.4f} (±{np.std(recall_scores):.4f})")
    print(f"Average F1 Score: {np.mean(f1_scores):.4f} (±{np.std(f1_scores):.4f})")

    # Only proceed with visualization if raster data and profile are provided
    if best_model is not None and raster_data is not None and profile is not None:
        # Apply the same transformations to raster data using the best model's preprocessing
        best_scaler, best_pca = best_fold_data

        # Scale and transform raster data
        raster_data_scaled = best_scaler.transform(raster_data)
        raster_data_pca = best_pca.transform(raster_data_scaled)

        # Get probabilities
        probability_map = best_model.predict_proba(raster_data_pca)[:, 1]

        # Reshape probabilities
        height, width = profile['height'], profile['width']
        probability_map = probability_map.reshape(height, width)

        mean_prob = np.mean(probability_map)
        std_dev_prob = np.std(probability_map)


        # Define thresholds using mean and standard deviation
        low_threshold = mean_prob - std_dev_prob
        moderate_low_threshold = mean_prob - 0.5 * std_dev_prob
        moderate_threshold = mean_prob
        moderate_high_threshold = mean_prob + 0.5 * std_dev_prob
        high_threshold = mean_prob + 1 * std_dev_prob

        plot_raster_map(mean_prob, std_dev_prob, probability_map, 'LogisticRegression')

    return precision_scores, recall_scores, f1_scores, best_model, best_fold_data

precision_scores, recall_scores, lr_accuracies, best_model, best_fold_data = evaluate_logistic_regression(data_cleaned, y_cleaned, raster_data, profile)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import precision_recall_curve, auc, confusion_matrix
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
import seaborn as sns
import numpy as np
import rasterio
def evaluate_knn(X, y, raster_data, profile):
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    precision_scores = []
    recall_scores = []
    f1_scores = []
    scaler = StandardScaler()
    min_precision_threshold = 0.65

    # Track best model
    best_recall = -1
    best_precision = -1
    best_model = None
    best_scaler = None
    best_pca = None

    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):
        # Split and prepare data
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # Scale the data
        curr_scaler = StandardScaler()
        X_train_scaled = curr_scaler.fit_transform(X_train)
        X_test_scaled = curr_scaler.transform(X_test)

        # Perform PCA
        curr_pca = PCA(n_components=13)
        X_train_pca = curr_pca.fit_transform(X_train_scaled)
        X_test_pca = curr_pca.transform(X_test_scaled)

        # Train model
        fold_model = KNeighborsClassifier(n_neighbors=4)
        fold_model.fit(X_train_pca, y_train)

        # Get probabilities
        y_prob = fold_model.predict_proba(X_test_pca)[:, 1]

        precision, recall, thresholds = precision_recall_curve(y_test, y_prob)

        optimal_idx = -1
        max_recall = -1
        curr_max_precision_idx = np.argmax(precision[:-1])

        for idx in range(len(thresholds)):
            if precision[idx] >= min_precision_threshold:
                if recall[idx] > max_recall:
                    max_recall = recall[idx]
                    optimal_idx = idx

        if optimal_idx == -1:
            optimal_idx = curr_max_precision_idx
            print(f"Fold {fold}: Using highest precision available: {precision[optimal_idx]:.4f}, Recall: {recall[optimal_idx]:.4f}")
        else:
            print(f"Fold {fold}: Found precision ≥ 0.65: {precision[optimal_idx]:.4f}, Recall: {recall[optimal_idx]:.4f}")
            if recall[optimal_idx] > best_recall:
                best_recall = recall[optimal_idx]
                best_precision = precision[optimal_idx]
                best_model = fold_model
                best_scaler = curr_scaler
                best_pca = curr_pca

        f1_score = 2 * (precision[optimal_idx] * recall[optimal_idx]) / (precision[optimal_idx] + recall[optimal_idx])
        precision_scores.append(precision[optimal_idx])
        recall_scores.append(recall[optimal_idx])
        f1_scores.append(f1_score)

    print(f"\nAverage Precision: {np.mean(precision_scores):.3f} ±{np.std(precision_scores):.3f} ")
    print(f"Average Recall: {np.mean(recall_scores):.3f} ±{np.std(recall_scores):.3f}")
    print(f"Average F1 Score: {np.mean(f1_scores):.3f} ±{np.std(f1_scores):.3f}")

    # Generate and display probability map using best model
    if best_model is not None:
       # Scale and transform raster data
        raster_data_scaled = best_scaler.transform(raster_data)
        raster_data_pca = best_pca.transform(raster_data_scaled)

        # Get probabilities
        probability_map = best_model.predict_proba(raster_data_pca)[:, 1]

        # Reshape probabilities
        height, width = profile['height'], profile['width']
        probability_map = probability_map.reshape(height, width)

        mean_prob = np.mean(probability_map)
        std_dev_prob = np.std(probability_map)

        plot_raster_map(mean_prob, std_dev_prob, probability_map, 'KNN')

    return precision_scores, recall_scores, f1_scores, best_model, (best_scaler, best_pca)

# Run the evaluation
precision_scores, recall_scores, knn_accuracies, best_model, best_transformers = evaluate_knn(data_cleaned, y_cleaned, raster_data, profile)

from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import precision_recall_curve, auc, confusion_matrix
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
import seaborn as sns
import numpy as np
import rasterio
def evaluate_svm(X, y, raster_data, profile):
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    precision_scores = []
    recall_scores = []
    f1_scores = []
    scaler = StandardScaler()
    min_precision_threshold = 0.65

    # Track best model
    best_recall = -1
    best_precision = -1
    best_model = None
    best_fold_data = None
    best_scaler = None
    best_pca = None

    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):
        # Split and prepare data
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # Scale the data
        curr_scaler = StandardScaler()
        X_train_scaled = curr_scaler.fit_transform(X_train)
        X_test_scaled = curr_scaler.transform(X_test)

        # Perform PCA
        curr_pca = PCA(n_components=13)
        X_train_pca = curr_pca.fit_transform(X_train_scaled)
        X_test_pca = curr_pca.transform(X_test_scaled)

        # Train model
        fold_model = SVC(probability=True, kernel='rbf', random_state=42)
        fold_model.fit(X_train_pca, y_train)

        # Get probabilities
        y_prob = fold_model.predict_proba(X_test_pca)[:, 1]

        precision, recall, thresholds = precision_recall_curve(y_test, y_prob)

        optimal_idx = -1
        max_recall = -1
        curr_max_precision_idx = np.argmax(precision[:-1])

        for idx in range(len(thresholds)):
            if precision[idx] >= min_precision_threshold:
                if recall[idx] > max_recall:
                    max_recall = recall[idx]
                    optimal_idx = idx

        if optimal_idx == -1:
            optimal_idx = curr_max_precision_idx
            print(f"Fold {fold}: Using highest precision available: {precision[optimal_idx]:.4f}, Recall: {recall[optimal_idx]:.4f}")
        else:
            print(f"Fold {fold}: Found precision ≥ 0.65: {precision[optimal_idx]:.4f}, Recall: {recall[optimal_idx]:.4f}")
            if recall[optimal_idx] > best_recall:
                best_recall = recall[optimal_idx]
                best_precision = precision[optimal_idx]
                best_model = fold_model
                best_scaler = curr_scaler
                best_pca = curr_pca

        f1_score = 2 * (precision[optimal_idx] * recall[optimal_idx]) / (precision[optimal_idx] + recall[optimal_idx])
        precision_scores.append(precision[optimal_idx])
        recall_scores.append(recall[optimal_idx])
        f1_scores.append(f1_score)

    print(f"\nAverage Precision: {np.mean(precision_scores):.3f} (±{np.std(precision_scores):.3f})")
    print(f"Average Recall: {np.mean(recall_scores):.3f} (±{np.std(recall_scores):.3f})")
    print(f"Average F1 Score: {np.mean(f1_scores):.3f} ±{np.std(f1_scores):.3f}")
    # Generate prediction map using best model
    if best_model is not None:
        # Scale and transform raster data
        raster_data_scaled = best_scaler.transform(raster_data)
        raster_data_pca = best_pca.transform(raster_data_scaled)
        # Get probabilities
        probability_map = best_model.predict_proba(raster_data_pca)[:, 1]
        mean_prob = np.mean(probability_map)
        std_dev_prob = np.std(probability_map)
        probability_map = probability_map.reshape(height, width)
        plot_raster_map(mean_prob, std_dev_prob, probability_map, 'SVM')

    return precision_scores, recall_scores, f1_scores, best_model, (best_scaler, best_pca)

# Run the evaluation
precision_scores, recall_scores, svm_accuracies, best_model, best_transformers = evaluate_svm(data_cleaned, y_cleaned, raster_data, profile)

from xgboost import XGBClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import precision_recall_curve, auc, confusion_matrix
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
import seaborn as sns
import numpy as np
import rasterio
def evaluate_xgboost(X, y):
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    precision_scores = []
    recall_scores = []
    f1_scores = []
    scaler = StandardScaler()
    min_precision_threshold = 0.65

    # Track best model
    best_recall = -1
    best_precision = -1
    best_model = None
    best_fold_data = None

    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):
        # Split and prepare data
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        # Scale the data
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # Perform PCA
        pca = PCA(n_components=13)
        X_train_pca = pca.fit_transform(X_train_scaled)
        X_test_pca = pca.transform(X_test_scaled)

        # Train model
        fold_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
        fold_model.fit(X_train_pca, y_train)

        # Get probabilities
        y_prob = fold_model.predict_proba(X_test_pca)[:, 1]

        # Calculate precision-recall curve
        precision, recall, thresholds = precision_recall_curve(y_test, y_prob)

        # Find optimal threshold
        optimal_idx = -1
        max_recall = -1
        curr_max_precision_idx = np.argmax(precision[:-1])

        for idx in range(len(thresholds)):
            if precision[idx] >= min_precision_threshold:
                if recall[idx] > max_recall:
                    max_recall = recall[idx]
                    optimal_idx = idx

        if optimal_idx == -1:
            optimal_idx = curr_max_precision_idx
            print(f"Fold {fold}: Using highest precision available: {precision[optimal_idx]:.4f}, Recall: {recall[optimal_idx]:.4f}")
        else:
            print(f"Fold {fold}: Found precision ≥ 0.65: {precision[optimal_idx]:.4f}, Recall: {recall[optimal_idx]:.4f}")
            if recall[optimal_idx] > best_recall:
                best_recall = recall[optimal_idx]
                best_precision = precision[optimal_idx]
                best_model = fold_model
                best_pca = pca
                best_scaler = scaler
                best_fold_data = (scaler, pca)

        f1_score = 2 * (precision[optimal_idx] * recall[optimal_idx]) / (precision[optimal_idx] + recall[optimal_idx])
        precision_scores.append(precision[optimal_idx])
        recall_scores.append(recall[optimal_idx])
        f1_scores.append(f1_score)

        print(f"\nAverage Precision: {np.mean(precision_scores):.3f} ±{np.std(precision_scores):.3f}")
        print(f"Average Recall: {np.mean(recall_scores):.3f} (±{np.std(recall_scores):.3f})")
        print(f"Average F1 Score: {np.mean(f1_scores):.3f} (±{np.std(f1_scores):.3f})")
    if best_model is not None:
        # Scale and transform raster data
        raster_data_scaled = best_scaler.transform(raster_data)
        raster_data_pca = best_pca.transform(raster_data_scaled)
        # Get probabilities
        probability_map = best_model.predict_proba(raster_data_pca)[:, 1]
        mean_prob = np.mean(probability_map)
        std_dev_prob = np.std(probability_map)
        probability_map = probability_map.reshape(height, width)
        plot_raster_map(mean_prob, std_dev_prob, probability_map, 'XGBoost')

    return precision_scores, recall_scores, f1_scores, best_model, best_fold_data

# Run the evaluation
precision_scores, recall_scores, xgb_accuracies, best_model, best_fold_data = evaluate_xgboost(data_cleaned, y_cleaned)

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.model_selection import cross_val_score, KFold

# Define the models in a list for easier iteration
# Combine all accuracies into a single DataFrame for seaborn
print(accuracies_all)
print(xgb_accuracies)
print(lr_accuracies)
print(knn_accuracies)
print(svm_accuracies)

plot_data = {
    'Accuracy': (
        accuracies_all +
        xgb_accuracies +
        lr_accuracies +
        knn_accuracies +
        svm_accuracies
    ),
    'PCA Selection': (
        ['Random Forest'] * len(accuracies_all) +
        ['XGBoost'] * len(xgb_accuracies) +
        ['Logistic Regression'] * len(lr_accuracies) +
        ['K-Nearest Neighbors'] * len(knn_accuracies) +
        ['Support Vector Machine'] * len(svm_accuracies)
    )
}

# Create a DataFrame
accuracy_df = pd.DataFrame(plot_data)
accuracy_df['Accuracy'] = pd.to_numeric(accuracy_df['Accuracy'])

# Calculate and print statistics for each PCA selection
stats = accuracy_df.groupby('PCA Selection')['Accuracy'].agg(['mean', 'median', 'std', 'min', 'max'])
print(stats)

# Set up the matplotlib figure
plt.figure(figsize=(12, 8))

# Create a boxplot
ax = sns.boxplot(x='PCA Selection', y='Accuracy', data=accuracy_df)

# Set plot title and labels
plt.title('Distribution of F1-Score by Model', fontsize=16)
plt.xlabel('Model Name', fontsize=14)
plt.ylabel('F1-Score', fontsize=14)

# Add mean and std text annotations
for i, model in enumerate(stats.index):
    mean_val = stats.loc[model, 'mean']
    std_val = stats.loc[model, 'std']
    text = f'μ = {mean_val:.3f}\nσ = {std_val:.3f}'
    ax.text(i, stats.loc[model, 'min'] - 0.05, text,
            horizontalalignment='center', size='medium',
            color='black', weight='semibold',
            bbox=dict(facecolor='white', alpha=0.8, edgecolor='gray', boxstyle='round,pad=0.5'))

# Show the plot
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.tight_layout()
plt.ylim(bottom=stats['min'].min() - 0.15)  # Adjust bottom limit to make room for annotations
plt.show()